{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Research\n",
    "\n",
    "One of the classic cross-business Agentic use cases! This is huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">A Deep Research agent is broadly applicable to any business area, and to your own day-to-day activities. You can make use of this yourself!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you find this lab useful! I would love to connect on LinkedIn: https://www.linkedin.com/in/kyranank/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upgrades to Original System (Rough Notes)\n",
    "\n",
    "- When given a query, come up with 3 questions that will help answer the query\n",
    "    - Then come up with a search query to answer each question\n",
    "- Incorporate handoffs and using agents as tools\n",
    "    - Agents as Tools: 1 Google Search agent and 1 OpenAI Web Search agent. The research manager will decide if more queries are needed (and can call planner_agent again), or if need to run again.\n",
    "    - Agents as Tools: 1 question formulator agent and 1 search planner agent which get used by the research manager in sequence.\n",
    "    - Handoff the research to the writer agent\n",
    "    - Handoff the report to the editor agent\n",
    "\n",
    "PLAN\n",
    "- Create & test question_formulator_agent\n",
    "    - Given a query, formulate X research questions to help answer the query\n",
    "    - Test with a query\n",
    "    - Convert to .as_tool()\n",
    "- Adjust previous planner_agent & test\n",
    "    - Use the question_formulator_agent as a tool to generate questions\n",
    "    - Create 1 search query to answer each 1 of the questions\n",
    "    - Test with simulated questions\n",
    "    - Convert to .as_tool()\n",
    "- Create & test gemini_search_agent\n",
    "    - Someone has a version in the community contributions folder\n",
    "    - Take the list of queries and perform a search for each one\n",
    "    - Test with simulated query list\n",
    "    - Convert to .as_tool()\n",
    "- Adjust previous openai_search_agent & test\n",
    "    - Take the list of queries and perform a search for each one\n",
    "    - Test with simulated query list\n",
    "    - Convert to .as_tool()\n",
    "- Create an editor_agent\n",
    "    - Receives the report and edits it to a professional level\n",
    "    - Returns the same as writer_agent\n",
    "- Adjust the writer_agent\n",
    "    - Receives the research, writes a report, also returns a markdown report\n",
    "    - Handsoff to editor_agent\n",
    "- Create a research_manager_agent\n",
    "    - Given a query use the planner_agent to generate search queries to research the query\n",
    "    - Next use the gemini_search_agent and openai_search_agents to conduct the search queries. They should each be used once for every search query. That way you receive two different results to consider for each query for the final research report. If you believe more information is needed to address the query, you can use the planner_agent only one additional time followed by the gemini_search_agent and the gemini_search_agent to gather additional research. You will then handoff this research to the writer_agent to write a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, WebSearchTool, trace, Runner, function_tool, handoff, set_default_openai_client, set_tracing_export_api_key\n",
    "from agents.model_settings import ModelSettings\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import os\n",
    "from sendgrid.helpers.mail import Mail, Email, To, Content\n",
    "from typing import Dict\n",
    "from IPython.display import display, Markdown\n",
    "from agents import OpenAIChatCompletionsModel\n",
    "from openai import AsyncOpenAI, AsyncAzureOpenAI\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_client = AsyncAzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-08-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=\"gtp-4o\"\n",
    ")\n",
    "\n",
    "openai = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "set_default_openai_client(openai_client);\n",
    "set_tracing_export_api_key(openai);\n",
    "\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "gemini = AsyncOpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Formulator Agent\n",
    "- Create & test question_formulator_agent\n",
    "    - Given a query, formulate X research questions to help answer the query\n",
    "    - Test with a query\n",
    "    - Convert to .as_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"You are a helpful research assistant. Given a query, formulate a set of research questions \\\n",
    "that when answered will help answer or address the query. Output 3 questions to research.\"\n",
    "\n",
    "class ResearchQuestionItem(BaseModel):\n",
    "    reason: str = Field(description=\"Your reasoning for why this question is important to address the query.\")\n",
    "    question: str = Field(description=\"The research question to use to conduct further research regarding the query.\")\n",
    "\n",
    "class ResearchQuestionPlan(BaseModel):\n",
    "    questions: list[ResearchQuestionItem] = Field(description=\"A list of research questions to research to best answer the query.\")\n",
    "\n",
    "question_formulator_agent = Agent(\n",
    "    name=\"Question Formulator Agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=OpenAIChatCompletionsModel(openai_client=openai_client, model=\"gpt-4o\"),\n",
    "    output_type=ResearchQuestionPlan,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions=[ResearchQuestionItem(reason='Understanding the most current frameworks will provide insights into the latest capabilities, trends, and tools available for developing AI agents in 2025.', question='What are the most popular AI agent frameworks available in 2025?'), ResearchQuestionItem(reason='Comparing the features of these frameworks will help in identifying which framework might be best suited for specific use cases or technical requirements.', question='What are the key features and differences among the leading AI agent frameworks in 2025?'), ResearchQuestionItem(reason='Exploring adoption trends among developers and companies can reveal the frameworks that are gaining traction in the industry, which may reflect their effectiveness or ease of use.', question='Which AI agent frameworks are gaining the most adoption and why in 2025?')]\n"
     ]
    }
   ],
   "source": [
    "message = \"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "with trace(\"Test - Question Formulator Agent\"):\n",
    "    result = await Runner.run(question_formulator_agent, message)\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionTool(name='question_formulator_agent', description='Generate research questions', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'question_formulator_agent_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x00000246C94367A0>, strict_json_schema=True, is_enabled=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = \"Generate research questions\"\n",
    "\n",
    "tool_question_formulator = question_formulator_agent.as_tool(tool_name=\"question_formulator_agent\", tool_description=description)\n",
    "\n",
    "tools_for_planner_agent = [tool_question_formulator]\n",
    "\n",
    "tools_for_planner_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planner Agent\n",
    "- Adjust previous planner_agent & test\n",
    "    - Use the question_formulator_agent as a tool to generate questions\n",
    "    - Create 1 search query to answer each 1 of the questions\n",
    "    - Test with simulated questions\n",
    "    - Convert to .as_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"You are a helpful research assistant. Given a query you will use the question_formulator_agent as a tool to \\\n",
    "come up with a set of questions. Your role is to create 1 web search for each question to perform to best answer the query. \\\n",
    "Output the web search terms to query for, there should be exactly as many web search queries as questions you received.\"\n",
    "\n",
    "class WebSearchItem(BaseModel):\n",
    "    reason: str = Field(description=\"Your reasoning for why this search is important to the query and will answer the question.\")\n",
    "    query: str = Field(description=\"The search term to use for the web search.\")\n",
    "\n",
    "class WebSearchPlan(BaseModel):\n",
    "    searches: list[WebSearchItem] = Field(description=\"A list of web searches to perform to best answer the query.\")\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"Planner Agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=OpenAIChatCompletionsModel(openai_client=openai_client, model=\"gpt-4o\"),\n",
    "    output_type=WebSearchPlan,\n",
    "    tools=tools_for_planner_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searches=[WebSearchItem(reason='Identifying the latest AI agent frameworks will provide a comprehensive understanding of the most advanced tools being utilized in 2025.', query='latest AI agent frameworks 2025'), WebSearchItem(reason='Comparing with popular frameworks used previously helps to understand the evolution, improvements, and possible shifts in preferences.', query='AI agent frameworks 2025 vs 2023'), WebSearchItem(reason='Understanding these features can help determine the strengths and suitability of these frameworks for specific applications.', query='features of AI agent frameworks 2025')]\n"
     ]
    }
   ],
   "source": [
    "message = \"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "with trace(\"Test - Planner Agent\"):\n",
    "    result = await Runner.run(planner_agent, message)\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionTool(name='planner_agent', description='Generate web search terms', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'planner_agent_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x00000246CD2B5DA0>, strict_json_schema=True, is_enabled=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = \"Generate web search terms\"\n",
    "\n",
    "tool_planner_agent = planner_agent.as_tool(tool_name=\"planner_agent\", tool_description=description)\n",
    "tools_for_research_manager_agent = [tool_planner_agent]\n",
    "tools_for_research_manager_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini Search Agent\n",
    "- Create & test gemini_search_agent\n",
    "    - Someone has a version in the community contributions folder\n",
    "    - Take the list of queries and perform a search for each one\n",
    "    - Test with simulated query list\n",
    "    - Convert to .as_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai\"\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_CUSTOM_SEARCH_API_KEY = os.getenv(\"GOOGLE_CUSTOM_SEARCH_API_KEY\")\n",
    "GOOGLE_CSE_ID = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "\n",
    "gemini_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "gemini_model = OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\",openai_client=gemini_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool for Web Search - Google doesn't offer a remote WebSearchTool like OpenAI\n",
    "# Need to set up Google Programmable Search / Custom Search API and get a key + search engine ID\n",
    "\n",
    "@function_tool\n",
    "async def google_web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs a Google Search and returns a string of concatenated result snippets.\n",
    "    \"\"\"\n",
    "    endpoint = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        \"key\": GOOGLE_CUSTOM_SEARCH_API_KEY,\n",
    "        \"cx\": GOOGLE_CSE_ID,\n",
    "        \"q\": query,\n",
    "        \"num\": 5,  # Number of results to fetch\n",
    "    }\n",
    "\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Google Search API error {response.status_code}: {response.text}\")\n",
    "\n",
    "    data = response.json()\n",
    "    items = data.get(\"items\", [])\n",
    "\n",
    "    if not items:\n",
    "        return \"No results found.\"\n",
    "\n",
    "    # Combine title and snippet for each result\n",
    "    result_texts = []\n",
    "    for item in items:\n",
    "        title = item.get(\"title\", \"\").strip()\n",
    "        snippet = item.get(\"snippet\", \"\").strip()\n",
    "        link = item.get(\"link\", \"\").strip()\n",
    "        result_texts.append(f\"{title}\\n{snippet}\\n{link}\")\n",
    "\n",
    "    summary = \"\\n\\n\".join(result_texts)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"You are a research assistant. Given a web search term, you search the web using the google_web_search tool \\\n",
    "for that term and produce a concise summary of the results. The summary must 5-8 paragraphs and between 500-1000 words \\\n",
    "words. Capture the main points. Write succintly, add evidence/facts, no need to have complete sentences or good \\\n",
    "grammar. This will be consumed by someone synthesizing a report, so it's vital you capture the \\\n",
    "essence and ignore any fluff. Do not include any additional commentary other than the summary itself.\"\n",
    "\n",
    "gemini_search_agent = Agent(\n",
    "    name=\"Gemini Search Agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[google_web_search],\n",
    "    model=gemini_model,\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The search results provide an overview of AI agent frameworks that were prominent or updated in 2025. Key frameworks mentioned include LangChain, Transformers Agents, and others. The results also highlight the expanding nature of AI agent frameworks and their evolving capabilities.\n",
       "\n",
       "**Key AI Agent Frameworks in 2025:**\n",
       "\n",
       "*   **LangChain:**  Ecosystem constantly growing with new community-contributed elements, tools, and connectors being introduced regularly.\n",
       "\n",
       "*   **Transformers Agents:** Introduced by Hugging Face, leveraging the power of transformer models.\n",
       "\n",
       "**General Trends and Concepts:**\n",
       "\n",
       "*   **Agentic Architecture:** Refers to the structure and design of agentic AI frameworks, shaping the workflow structure to automate AI models.\n",
       "*   **Growing Ecosystem:** The field of AI agent frameworks is continuously expanding and evolving, with new frameworks and updates emerging regularly.\n",
       "\n",
       "The search results suggest a dynamic landscape for AI agent frameworks in 2025, characterized by ongoing development, new introductions, and increasing adoption in various applications.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = \"notable AI agent frameworks introduced or updated in 2025\"\n",
    "\n",
    "with trace(\"Test - Gemini Search Agent\"):\n",
    "    result = await Runner.run(gemini_search_agent, message)\n",
    "\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"Search the web using Google Search\"\n",
    "\n",
    "tool_google_search = gemini_search_agent.as_tool(tool_name=\"gemini_search_agent\", tool_description=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionTool(name='planner_agent', description='Generate web search terms', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'planner_agent_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x00000246CD2B5DA0>, strict_json_schema=True, is_enabled=True),\n",
       " FunctionTool(name='gemini_search_agent', description='Search the web using Google Search', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'gemini_search_agent_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x00000246CD2B7E20>, strict_json_schema=True, is_enabled=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_for_research_manager_agent.append(tool_google_search)\n",
    "tools_for_research_manager_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Search Agent\n",
    "- Adjust previous openai_search_agent & test\n",
    "    - Take the list of queries and perform a search for each one\n",
    "    - Test with simulated query list\n",
    "    - Convert to .as_tool()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"You are a research assistant. Given a web search term, you search the web \\\n",
    "for that term and produce a concise summary of the results. The summary must 5-8 paragraphs and between 500-1000 words \\\n",
    "words. Capture the main points. Write succintly, add evidence/facts, no need to have complete sentences or good \\\n",
    "grammar. This will be consumed by someone synthesizing a report, so it's vital you capture the \\\n",
    "essence and ignore any fluff. Do not include any additional commentary other than the summary itself.\"\n",
    "\n",
    "openai_search_agent = Agent(\n",
    "    name=\"Search Agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[WebSearchTool(search_context_size=\"low\")],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: Unsupported data type. (request_id: None)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Unsupported data type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33mnotable AI agent frameworks introduced or updated in 2025\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trace(\u001b[33m\"\u001b[39m\u001b[33mSearch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(openai_search_agent, message)\n\u001b[32m      6\u001b[39m display(Markdown(result.final_output))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\agents\\run.py:199\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run a workflow starting at the given agent. The agent will run in a loop until a final\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[33;03moutput is generated. The loop runs like so:\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[33;03m1. The agent is invoked with the given input.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    196\u001b[39m \u001b[33;03m    agent. Agents may perform handoffs, so we don't know the specific type of the output.\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    198\u001b[39m runner = DEFAULT_AGENT_RUNNER\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner.run(\n\u001b[32m    200\u001b[39m     starting_agent,\n\u001b[32m    201\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    202\u001b[39m     context=context,\n\u001b[32m    203\u001b[39m     max_turns=max_turns,\n\u001b[32m    204\u001b[39m     hooks=hooks,\n\u001b[32m    205\u001b[39m     run_config=run_config,\n\u001b[32m    206\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    207\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\agents\\run.py:395\u001b[39m, in \u001b[36mAgentRunner.run\u001b[39m\u001b[34m(self, starting_agent, input, **kwargs)\u001b[39m\n\u001b[32m    390\u001b[39m logger.debug(\n\u001b[32m    391\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    392\u001b[39m )\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    396\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_input_guardrails(\n\u001b[32m    397\u001b[39m             starting_agent,\n\u001b[32m    398\u001b[39m             starting_agent.input_guardrails\n\u001b[32m    399\u001b[39m             + (run_config.input_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[32m    400\u001b[39m             copy.deepcopy(\u001b[38;5;28minput\u001b[39m),\n\u001b[32m    401\u001b[39m             context_wrapper,\n\u001b[32m    402\u001b[39m         ),\n\u001b[32m    403\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_single_turn(\n\u001b[32m    404\u001b[39m             agent=current_agent,\n\u001b[32m    405\u001b[39m             all_tools=all_tools,\n\u001b[32m    406\u001b[39m             original_input=original_input,\n\u001b[32m    407\u001b[39m             generated_items=generated_items,\n\u001b[32m    408\u001b[39m             hooks=hooks,\n\u001b[32m    409\u001b[39m             context_wrapper=context_wrapper,\n\u001b[32m    410\u001b[39m             run_config=run_config,\n\u001b[32m    411\u001b[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    412\u001b[39m             tool_use_tracker=tool_use_tracker,\n\u001b[32m    413\u001b[39m             previous_response_id=previous_response_id,\n\u001b[32m    414\u001b[39m         ),\n\u001b[32m    415\u001b[39m     )\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    417\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_single_turn(\n\u001b[32m    418\u001b[39m         agent=current_agent,\n\u001b[32m    419\u001b[39m         all_tools=all_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m    427\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    428\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\agents\\run.py:905\u001b[39m, in \u001b[36mAgentRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    902\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m    903\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m    906\u001b[39m     agent,\n\u001b[32m    907\u001b[39m     system_prompt,\n\u001b[32m    908\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    909\u001b[39m     output_schema,\n\u001b[32m    910\u001b[39m     all_tools,\n\u001b[32m    911\u001b[39m     handoffs,\n\u001b[32m    912\u001b[39m     context_wrapper,\n\u001b[32m    913\u001b[39m     run_config,\n\u001b[32m    914\u001b[39m     tool_use_tracker,\n\u001b[32m    915\u001b[39m     previous_response_id,\n\u001b[32m    916\u001b[39m     prompt_config,\n\u001b[32m    917\u001b[39m )\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m    920\u001b[39m     agent=agent,\n\u001b[32m    921\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m    930\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m    931\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\agents\\run.py:1066\u001b[39m, in \u001b[36mAgentRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id, prompt_config)\u001b[39m\n\u001b[32m   1063\u001b[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001b[32m   1064\u001b[39m model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n\u001b[32m   1067\u001b[39m     system_instructions=system_prompt,\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1069\u001b[39m     model_settings=model_settings,\n\u001b[32m   1070\u001b[39m     tools=all_tools,\n\u001b[32m   1071\u001b[39m     output_schema=output_schema,\n\u001b[32m   1072\u001b[39m     handoffs=handoffs,\n\u001b[32m   1073\u001b[39m     tracing=get_model_tracing_impl(\n\u001b[32m   1074\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m   1075\u001b[39m     ),\n\u001b[32m   1076\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m   1077\u001b[39m     prompt=prompt_config,\n\u001b[32m   1078\u001b[39m )\n\u001b[32m   1080\u001b[39m context_wrapper.usage.add(new_response.usage)\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\agents\\models\\openai_responses.py:82\u001b[39m, in \u001b[36mOpenAIResponsesModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id, prompt)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m response_span(disabled=tracing.is_disabled()) \u001b[38;5;28;01mas\u001b[39;00m span_response:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     83\u001b[39m             system_instructions,\n\u001b[32m     84\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     85\u001b[39m             model_settings,\n\u001b[32m     86\u001b[39m             tools,\n\u001b[32m     87\u001b[39m             output_schema,\n\u001b[32m     88\u001b[39m             handoffs,\n\u001b[32m     89\u001b[39m             previous_response_id,\n\u001b[32m     90\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     91\u001b[39m             prompt=prompt,\n\u001b[32m     92\u001b[39m         )\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001b[32m     95\u001b[39m             logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLLM responded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\agents\\models\\openai_responses.py:256\u001b[39m, in \u001b[36mOpenAIResponsesModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, stream, prompt)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    246\u001b[39m     logger.debug(\n\u001b[32m    247\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling LLM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with input:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson.dumps(list_input,\u001b[38;5;250m \u001b[39mindent=\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    253\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrevious response id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprevious_response_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    254\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.responses.create(\n\u001b[32m    257\u001b[39m     previous_response_id=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(previous_response_id),\n\u001b[32m    258\u001b[39m     instructions=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(system_instructions),\n\u001b[32m    259\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    260\u001b[39m     \u001b[38;5;28minput\u001b[39m=list_input,\n\u001b[32m    261\u001b[39m     include=converted_tools.includes,\n\u001b[32m    262\u001b[39m     tools=converted_tools.tools,\n\u001b[32m    263\u001b[39m     prompt=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(prompt),\n\u001b[32m    264\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n\u001b[32m    265\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n\u001b[32m    266\u001b[39m     truncation=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.truncation),\n\u001b[32m    267\u001b[39m     max_output_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001b[32m    268\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    269\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    270\u001b[39m     stream=stream,\n\u001b[32m    271\u001b[39m     extra_headers={**_HEADERS, **(model_settings.extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})},\n\u001b[32m    272\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    273\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    274\u001b[39m     text=response_format,\n\u001b[32m    275\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.store),\n\u001b[32m    276\u001b[39m     reasoning=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.reasoning),\n\u001b[32m    277\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n\u001b[32m    278\u001b[39m     **(model_settings.extra_args \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    279\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\openai\\resources\\responses\\responses.py:1918\u001b[39m, in \u001b[36mAsyncResponses.create\u001b[39m\u001b[34m(self, background, include, input, instructions, max_output_tokens, metadata, model, parallel_tool_calls, previous_response_id, prompt, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1887\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1888\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1889\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1916\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1917\u001b[39m ) -> Response | AsyncStream[ResponseStreamEvent]:\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1919\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/responses\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1920\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   1921\u001b[39m             {\n\u001b[32m   1922\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbackground\u001b[39m\u001b[33m\"\u001b[39m: background,\n\u001b[32m   1923\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m: include,\n\u001b[32m   1924\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1925\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: instructions,\n\u001b[32m   1926\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_output_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_output_tokens,\n\u001b[32m   1927\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1928\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1929\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1930\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprevious_response_id\u001b[39m\u001b[33m\"\u001b[39m: previous_response_id,\n\u001b[32m   1931\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt,\n\u001b[32m   1932\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m: reasoning,\n\u001b[32m   1933\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1934\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1935\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   1936\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1937\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text,\n\u001b[32m   1938\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1939\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1940\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1941\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtruncation\u001b[39m\u001b[33m\"\u001b[39m: truncation,\n\u001b[32m   1942\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1943\u001b[39m             },\n\u001b[32m   1944\u001b[39m             response_create_params.ResponseCreateParamsStreaming\n\u001b[32m   1945\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   1946\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m response_create_params.ResponseCreateParamsNonStreaming,\n\u001b[32m   1947\u001b[39m         ),\n\u001b[32m   1948\u001b[39m         options=make_request_options(\n\u001b[32m   1949\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   1950\u001b[39m         ),\n\u001b[32m   1951\u001b[39m         cast_to=Response,\n\u001b[32m   1952\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1953\u001b[39m         stream_cls=AsyncStream[ResponseStreamEvent],\n\u001b[32m   1954\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1784\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1770\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1772\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1779\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1780\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1781\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1782\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1783\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1584\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1581\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1583\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1584\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1586\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1588\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Unsupported data type"
     ]
    }
   ],
   "source": [
    "message = \"notable AI agent frameworks introduced or updated in 2025\"\n",
    "\n",
    "with trace(\"Search\"):\n",
    "    result = await Runner.run(openai_search_agent, message)\n",
    "\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"Search the web using OpenAI's WebSearchTool\"\n",
    "\n",
    "tool_openai_search = openai_search_agent.as_tool(tool_name=\"openai_search_agent\", tool_description=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionTool(name='planner_agent', description='Generate web search terms', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'planner_agent_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x00000246CD2B5DA0>, strict_json_schema=True, is_enabled=True),\n",
       " FunctionTool(name='gemini_search_agent', description='Search the web using Google Search', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'gemini_search_agent_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x00000246CD2B7E20>, strict_json_schema=True, is_enabled=True),\n",
       " FunctionTool(name='openai_search_agent', description=\"Search the web using OpenAI's WebSearchTool\", params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'openai_search_agent_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x00000246CDFF1620>, strict_json_schema=True, is_enabled=True)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_for_research_manager_agent.append(tool_openai_search)\n",
    "tools_for_research_manager_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editor Agent\n",
    "- Create an editor_agent\n",
    "    - Receives the report and edits it to a professional level\n",
    "    - Returns the same as writer_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportData(BaseModel):\n",
    "    short_summary: str = Field(description=\"A short 2-3 sentence summary of the findings.\")\n",
    "    markdown_report: str = Field(description=\"The final report\")\n",
    "    follow_up_questions: list[str] = Field(description=\"Suggested topics to research further\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = (\n",
    "    \"You are a senior editor tasked with editing and revising a cohesive report for a research query. \"\n",
    "    \"You will be provided with the report data including a short summary, full markdown_report, and some follow_up_questions\\n\"\n",
    "    \"You should first review the report, analyze the structure, correct grammar, spelling, sentence structure, etc. for profressionalism\"\n",
    "    \"Then, create a revised report using the original report as a basis and return that as your final output.\\n\"\n",
    "    \"The final output should be in markdown format, and it should be lengthy and detailed with FULL SENTENCES.\"\n",
    "    \"This is a research report, aim for 10-15 pages of content, AT LEAST 2000 words, maximum of 5000 words.\"\n",
    ")\n",
    "\n",
    "editor_agent = Agent(\n",
    "    name=\"Editor Agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=OpenAIChatCompletionsModel(openai_client=openai_client, model=\"gpt-4o\"),\n",
    "    output_type=ReportData\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writer Agent\n",
    "- Adjust the writer_agent\n",
    "    - Receives the research, writes a report, also returns a markdown report\n",
    "    - Handsoff to editor_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = (\n",
    "    \"You are a senior researcher tasked with writing a cohesive report for a research query. \"\n",
    "    \"You will be provided with the original query, and some initial research done by a research assistant.\\n\"\n",
    "    \"You should first come up with an outline for the report that describes the structure and \"\n",
    "    \"flow of the report. Then, generate the report using the research as a basis and return that as your final output.\\n\"\n",
    "    \"The final output should be in markdown format, and it should be lengthy and detailed. Aim \"\n",
    "    \"for 10-15 pages of content, at least 2000 words.\"\n",
    "    \"Once you have gathered all research results, hand off the complete set of research materials to the `editor_agent`.\\n\"\n",
    "    \"The `writer_agent` will be responsible for synthesizing the information into a final research report.\"\n",
    ")\n",
    "\n",
    "writer_agent = Agent(\n",
    "    name=\"Writer Agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=OpenAIChatCompletionsModel(openai_client=openai_client, model=\"gpt-4o\"),\n",
    "    output_type=ReportData,\n",
    "    handoffs=[handoff(editor_agent)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Manager Agent\n",
    "- Create a research_manager_agent\n",
    "    - Given a query use the planner_agent to generate search queries to research the query\n",
    "    - Next use the gemini_search_agent and openai_search_agents to conduct the search queries. They should each be used once for every search query. That way you receive two different results to consider for each query for the final research report. If you believe more information is needed to address the query, you can use the planner_agent only one additional time followed by the gemini_search_agent and the gemini_search_agent to gather additional research. You will then handoff this research to the writer_agent to write a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"\"\"\n",
    "You are a Research Manager Agent responsible for coordinating a multi-step research process to produce high-quality research reports.\n",
    "\n",
    "Follow this workflow precisely:\n",
    "\n",
    "1. **Planning Phase**\n",
    "   - When given a research query, always start by using the `planner_agent`.\n",
    "   - Use the `planner_agent` to generate a set of structured search queries. The planner will return these queries as a Pydantic model.\n",
    "\n",
    "2. **Initial Research Phase**\n",
    "   - For each search query provided by the planner, conduct research using both of the following agents:\n",
    "     - `gemini_search_agent`\n",
    "     - `openai_search_agent`\n",
    "   - You must use each of these search agents exactly once per search query. This ensures you gather two different perspectives for every query.\n",
    "\n",
    "3. **Supplemental Research (if necessary)**\n",
    "   - After reviewing the initial results, if you determine that additional information is required to adequately address the original research query, you may proceed to collect more research.\n",
    "   - To do this, you may call the `planner_agent` **only one additional time** to generate more search queries.\n",
    "   - For each additional search query, again use both:\n",
    "     - `gemini_search_agent`\n",
    "     - `openai_search_agent`\n",
    "   - Do not exceed this single additional round of planning and research.\n",
    "\n",
    "4. **Report Handoff**\n",
    "   - Once you have gathered all research results, hand off the complete set of research materials to the `writer_agent`.\n",
    "   - The `writer_agent` will be responsible for synthesizing the information into a final research report.\n",
    "\n",
    "Important Guidelines:\n",
    "- Always perform the research workflow in the sequence described: planner → search agents → (optional, only allowed to call 1 additional time) planner → search agents → writer.\n",
    "- Do not skip any steps or call the search agents before the planner.\n",
    "- DO NOT call the planner more than two (2) times TOTAL per query. You should only call it a maximum of 1 initial time and 1 additional time, for a total of 2 times.\n",
    "- Ensure all gathered results are organized clearly before passing them to the writer agent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_manager_agent = Agent(\n",
    "    name=\"Research Manager Agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=tools_for_research_manager_agent,\n",
    "    model=OpenAIChatCompletionsModel(openai_client=openai_client, model=\"gpt-4o\"),\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    "    handoffs=[handoff(writer_agent)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: Unsupported data type. (request_id: None)\n",
      "Error getting response: Unsupported data type. (request_id: None)\n",
      "Error getting response: Unsupported data type. (request_id: None)\n",
      "Error getting response: Unsupported data type. (request_id: None)\n",
      "Error getting response: Unsupported data type. (request_id: None)\n",
      "Error getting response: Unsupported data type. (request_id: None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Complete!\n"
     ]
    }
   ],
   "source": [
    "# RUN AGENTIC SYSTEM HERE!\n",
    "\n",
    "message = \"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "with trace(\"Search\"):\n",
    "    final_result = await Runner.run(research_manager_agent, message)\n",
    "    print(\"Report Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The AI agent frameworks of 2025 are characterized by their focus on collaborative teamwork, integration with existing systems, flexibility, and adaptability. Frameworks such as Microsoft AutoGen, LangChain, and CrewAI lead the development landscape. Developer preferences are influenced by factors such as ease of use, level of customization, and specific project requirements."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(final_result.final_output.short_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# The Latest AI Agent Frameworks in 2025\n",
       "\n",
       "## Introduction\n",
       "In 2025, AI agent frameworks have evolved considerably to meet the growing demands of sophisticated AI systems. This report delves into the most commonly used frameworks, their key features, and why developers favor certain platforms. This comprehensive analysis serves as a guide for those looking to understand and possibly implement the latest advancements in AI agent technology.\n",
       "\n",
       "## Common AI Agent Frameworks in 2025\n",
       "\n",
       "### Key Frameworks\n",
       "The AI technology landscape has seen several significant frameworks gaining popularity by 2025, each offering unique features and capabilities:\n",
       "\n",
       "1. **Microsoft AutoGen**: This open-source framework is particularly suited for creating and orchestrating AI agents and multi-agent systems. It benefits from seamless integration with Microsoft tools, enhancing its attractiveness for enterprises already invested in Microsoft's ecosystem.\n",
       "\n",
       "2. **LangChain**: Renowned for building effective AI workflows, LangChain emphasizes flexibility and ease of use, enabling developers to construct complex, automated processes efficiently.\n",
       "\n",
       "3. **LangGraph**: Complementary to LangChain, this framework specializes in advanced state management, which is critical for AI agents requiring robust, dynamic interaction management.\n",
       "\n",
       "4. **Phidata**: Known as an adaptive agent framework, Phidata offers customization and adaptability, making it a preferred choice for projects demanding precision and flexibility.\n",
       "\n",
       "5. **CrewAI**: This framework focuses on teamwork, facilitating the creation of AI agents that can effectively collaborate within teams, highlighting a shift towards more dynamic, group-oriented AI development.\n",
       "\n",
       "6. **Microsoft Semantic Kernel**: Another product from Microsoft, emphasizing both semantic capabilities and automated AI processes, showing the tech giant's commitment to comprehensive AI solutions.\n",
       "\n",
       "7. **Rasa**: Continuing its focus on conversational AI, Rasa remains a pivotal tool for developers creating interactive AI agents that require natural language processing and dialogue management.\n",
       "\n",
       "8. **JADE (Java Agent Development Framework)**: A stalwart in the field, JADE provides a solid Java-based environment for developing a wide range of AI agents.\n",
       "\n",
       "## Key Features and Innovations\n",
       "\n",
       "### Fundamental Attributes\n",
       "Current frameworks embody a set of core features and innovations designed to enhance AI development:\n",
       "\n",
       "- **Integration Capabilities**: Modern frameworks focus heavily on integration with existing systems to facilitate seamless deployment and usage across various platforms.\n",
       "\n",
       "- **Event-driven Architectures**: Many frameworks are adopting event-driven paradigms to improve responsiveness and efficiency, crucial for real-time AI operations.\n",
       "\n",
       "- **Pythonic Design**: The use of Python annotations and constructs leads to more intuitive and structured development processes, supporting a wide base of developers familiar with Python.\n",
       "\n",
       "- **Flexibility and Adaptability**: As the AI landscape is ever-evolving, frameworks that offer flexibility and adaptability are highly valued. They ensure that developments remain relevant and capable of integrating future technologies.\n",
       "\n",
       "### Advanced Features\n",
       "Some frameworks, such as OpenAI Gym, specialize in reinforcement learning to train AI agents more effectively, providing tools that are particularly useful for developing high-performance AI systems capable of complex decision-making.\n",
       "\n",
       "## Developer Preferences and Trends\n",
       "\n",
       "Developers in 2025 base their framework preferences on various qualitative and technical factors:\n",
       "\n",
       "- **Ease of Use**: Frameworks that offer simplified processes or intuitive interfaces enable developers to focus on creativity and problem-solving rather than technical hurdles.\n",
       "\n",
       "- **Level of Control**: Advanced frameworks like LangGraph provide deeper, more refined control over agent behaviors and interactions, appealing to seasoned developers dealing with intricate AI systems.\n",
       "\n",
       "- **Project Requirements**: The choice of framework often aligns with project-specific needs, such as the necessity for multi-agent collaboration or particular integration abilities.\n",
       "\n",
       "- **Community and Support**: Strong community backing and comprehensive support systems are influential in choosing a particular framework, ensuring that developers have access to troubleshooting and advice.\n",
       "\n",
       "## Conclusion\n",
       "The AI agent frameworks of 2025 reflect a blend of innovation, practicality, and collaborative capabilities. As these frameworks continue to evolve, they advance the possibilities in AI development, offering developers a range of tools that cater to both the broad and the specific needs of modern applications. Understanding these frameworks and their capabilities is essential for leveraging the full potential of AI in 2025.\n",
       "\n",
       "## References\n",
       "Gathering all references from current research and forums, predicted technological advancements, and statements from key technology developers."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(final_result.final_output.markdown_report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextensions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_graph\n\u001b[32m      3\u001b[39m draw_graph(research_manager_agent)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\agents\\extensions\\visualization.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgraphviz\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhandoffs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Handoff\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "from agents.extensions.visualization import draw_graph\n",
    "\n",
    "draw_graph(research_manager_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextensions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_graph\n\u001b[32m      2\u001b[39m draw_graph(writer_agent)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\agents\\extensions\\visualization.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgraphviz\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhandoffs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Handoff\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "from agents.extensions.visualization import draw_graph\n",
    "draw_graph(writer_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextensions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_graph\n\u001b[32m      2\u001b[39m draw_graph(editor_agent)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\cursoIA\\agents\\.venv\\Lib\\site-packages\\agents\\extensions\\visualization.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgraphviz\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhandoffs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Handoff\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "from agents.extensions.visualization import draw_graph\n",
    "draw_graph(editor_agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
